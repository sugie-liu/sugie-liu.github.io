相关论文
1、[Coarse-to-fine Semantic Localization with HD Map for Autonomous Driving in Structural Scenes](https://arxiv.org/pdf/2107.02557.pdf)
[图片]
如上图，定位分成了三部分：数据源、初始化以及跟踪部分。
1、数据源：
定位系统的输入包含有图像、GPS、轮式里程计以及高精地图。
图像：
为了找到HD map 元素和图像间的对应关系，本文应用了语义分割方法来提取图像中的语义信息，所提取的语义信息包括道路标记（LA）如车道线，柱状无图（PO），指示牌（SB）。
通过使用语义分割信息，采用非线性优化获取车辆的位姿信息。作者对语义分割中不同的元素采用不同的后处理方法。对于LA、PO采用腐蚀膨胀操作，
对于SB，通过Laplace transform提取边缘信息，然后通过形态学操作得到平滑可微的图像，经过形态学操作生成的代价地图使得位姿优化可以更快的收敛到正确的结果，最终经过处理的分割结果的像素值转换成0到1范围内。作者定义后处理的分割结果标记为$$I_s$$。

2、初始化部分
初始化模块用于获取在地图坐标系相对准确的位姿估计。作者引入鲁棒的精确的初始化方法，该方法是一个由粗到精的操作，粗略的初始位置由GPS给定。通过暴力搜索找到车辆在HD坐标系下的精确位置，搜索和优化的代价函数定义为各个语义标记的光度误差之和。即：
  $$cost = \sum_{i=0}^{n} \| I_s(\pi((T_{wb} * T_{bc})^{-1}P_w)) - 1.0\|_{2}$$
  式中，$$P_w$$为地图中元素位置，$$T_{bc}$$为相机外参。$$\pi$$为相机模型的投影方程。
3、跟踪部分
在跟踪阶段通过语义特征和先验地图对齐可以估计出车辆的位置。跟踪模块可以分成三部分
（1）k+1帧的位置$$T_{wb}^{k+1}$$,可以通过k帧$$T_{wb}^{k}$$以及其他传感器的测量信息$$T_{b}^{k{\rightarrow}k+1}$$计算得出。
$$T_{wb}^{k+1} = T_{wb}^{k} * T_b^{k{\rightarrow}k+1}$$
如果驾驶场景满足车辆纵向约束，则从全局地图截取局部地图，否则先进行纵向位置矫正流程。
Data association，计算重投影误差，采用非线性优化计算当前帧的初始值。为了保证计算结果的平滑性，采用滑窗方法，进行pose graph optimization。
